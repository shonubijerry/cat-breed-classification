{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install(pkg):\n",
    "  # for p in pkg:\n",
    "    !pip.main(['install', pkg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install('numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import array_to_img, img_to_array, load_img\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model, load_model\n",
    "import cv2\n",
    "\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    print(\"module 'google.colab' is installed\")\n",
    "except ModuleNotFoundError:\n",
    "    print(\"module 'mutagen' is not installed\")\n",
    "    # or\n",
    "    !pip install google-colab # the install function from the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# Set the path to the dataset directory\n",
    "train_dir = './data/cats/train'\n",
    "validation_dir = './data/cats/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set the image size and batch size\n",
    "img_size = (299, 299)\n",
    "batch_size = 32\n",
    "num_classes=6\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and create generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the train generator\n",
    "# Create image data generator with data augmentation for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# Create the validator generator\n",
    "# Create image data generator without data augmentation for the validation set\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_sample, _ = next(train_generator)\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i, x in enumerate(x_val_sample[:38]):\n",
    "    ax = plt.subplot(5, 7, i+1)\n",
    "    plt.imshow(x)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup base model and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the InceptionV3 model pre-trained on ImageNet without the top layer\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add a global average pooling layer and a dense layer with 256 units for classification\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# Add a final dense layer with the number of classes and a softmax activation\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Combine the base model and the top layers to create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model for 10 epochs\n",
    "num_epochs = 10\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.n // batch_size,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.n // batch_size)\n",
    "# Save the model\n",
    "model.save('cat_breed_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_names = {\n",
    "    0: 'American Shorthair',\n",
    "    1: 'Bengal',\n",
    "    2: 'Maine Coon',\n",
    "    3: 'Ragdoll',\n",
    "    4: 'Scottish Fold',\n",
    "    5: 'Sphynx'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# datapoints = model.history.history\n",
    "\n",
    "# history = {\n",
    "#   'train_acc': ['Training accuracy', datapoints['accuracy']],\n",
    "#   'test_acc': ['Validation accuracy', datapoints['val_accuracy']],\n",
    "#   'train_loss': ['Training loss', datapoints['loss']],\n",
    "#   'test_loss': ['Validation loss', datapoints['val_loss']]\n",
    "# }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(history):\n",
    "  title = 'Training/validation loss and accuracy'\n",
    "  \n",
    "  epochs = range(len(history['accuracy']))\n",
    "  plt.title(title)\n",
    "  plt.plot(epochs, history['accuracy'], label=\"Training accuracy\")\n",
    "  plt.plot(epochs, history['val_accuracy'], label=\"Validation accuracy\")\n",
    "  plt.plot(epochs, history['loss'], label=\"Training loss\")\n",
    "  plt.plot(epochs, history['val_loss'], label=\"Validation loss\")\n",
    "  plt.legend()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the cat breed classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('cat_breed_classification_model.h5')\n",
    "\n",
    "X_val_sample, _ = next(validation_generator)\n",
    "y_pred = model.predict(X_val_sample)\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "\n",
    "nb_sample = 10\n",
    "for i, (x, y) in enumerate(zip(X_val_sample[:nb_sample], y_pred[:nb_sample])):\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    predicted_class = np.argmax(y)\n",
    "    breed_name = breed_names[predicted_class]\n",
    "    title = 'Breed: '+breed_name + '\\n Accuracy: ' + str(np.max(y))\n",
    "    plt.imshow(x)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm to detect human face or cat breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import trained inceptionV3 model\n",
    "model = load_model('cat_breed_classification_model.h5')\n",
    "# import pretrained human face cascade\n",
    "face_cascade = cv2.CascadeClassifier(\"./haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# preprocessing images\n",
    "def tensor_3d_to_4d(img):\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def detect_human_face(img):\n",
    "  global face_cascade\n",
    "  isHuman = False\n",
    "  print(type(img))\n",
    "  \n",
    "  if (img is None): return isHuman\n",
    "  \n",
    "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  face = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "  for (x,y,w,h) in face:\n",
    "      img = cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),3)\n",
    "      isHuman = True\n",
    "\n",
    "  return isHuman\n",
    "\n",
    "def detect_cat_breed(img):\n",
    "  global model\n",
    "  y = model.predict(tensor_3d_to_4d(img))\n",
    "  \n",
    "  if (np.argmax(y) < 0.2): return False\n",
    "  \n",
    "  result = {}\n",
    "  predicted_class = np.argmax(y)\n",
    "  result['breed_name'] = breed_names[predicted_class]\n",
    "  result['accuracy'] = np.max(y)\n",
    "  \n",
    "  return result\n",
    "  \n",
    "def eval_image(img):\n",
    "  cat_breed = detect_cat_breed(img)\n",
    "  \n",
    "  if (detect_human_face(img)):\n",
    "    return 'You\\'re human\\n'\n",
    "  elif (cat_breed):\n",
    "    return cat_breed['breed_name'] +' breed of cat\\nI\\'m '+ str(cat_breed['accuracy']) +' sure'\n",
    "  else:\n",
    "    return 'Not human / cat\\n'\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test algorithm with human faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humans = [cv2.imread(file) for file in glob.glob(\"data/human/*.jpg\")]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "for i, image in enumerate(list(humans[0:10])):\n",
    "  image = cv2.resize(image, (224, 224))\n",
    "  ax = plt.subplot(3, 5, i+1)\n",
    "  title = eval_image(image)\n",
    "\n",
    "  cv_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  plt.imshow(cv_rgb)\n",
    "  plt.title(title)\n",
    "  plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [cv2.imread(file) for file in glob.glob(\"./data/different_cat_breeds/*.jpg\")]\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "for i, image in enumerate(cats[:10]):\n",
    "  if (image is None): continue\n",
    "  \n",
    "  ax = plt.subplot(3, 5, i+1)\n",
    "  \n",
    "  title = eval_image(image)\n",
    "  print(title)\n",
    "  cv_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  plt.imshow(image)\n",
    "  plt.title(title)\n",
    "  plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with other models (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 model without top layers\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers\n",
    "x = vgg.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Compile model\n",
    "vgg_model = Model(inputs=vgg.input, outputs=predictions)\n",
    "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = vgg_model.fit(train_generator, epochs=10, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d3a933a1b93f4b1cf4d7acc75de950c3048aefc4b1a3e983ad1536b77731996"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
